\documentclass[a4paper,11pt,titlepage]{article}
\parskip 3pt

%% %%%%%%%%%%%%%%%%%%%% BEGIN PACKAGES %%%%%%%%%%%%%%%%%%%%

%%\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}

\usepackage{fullpage}
\usepackage{url}
\usepackage{hyperref}
\hypersetup{pdfborder=0 0 0}

%% Images
\usepackage{graphicx}

%% Side-by-side images
\usepackage{subfig}

%% Drawing trees and other stuff
\usepackage{tikz}
\usetikzlibrary{trees,arrows}
\usepackage{amssymb}

%% Pseudocode
\usepackage[noend]{algorithmic}
\algsetup{indent=1.5em}

%%Code
\usepackage{listings}
\lstset{language=C++,breaklines=true}

%% Linux Libertine
\usepackage[T1]{fontenc}
\usepackage{libertine}
\renewcommand*\oldstylenums[1]{{\fontfamily{fxlj}\selectfont #1}}

%% %%%%%%%%%%%%%%%%%%%% END PACKAGES %%%%%%%%%%%%%%%%%%%%


%% %%%%%%%%%%%%%%%%%%%% BEGIN COMMANDS %%%%%%%%%%%%%%%%%%%%

\newcommand{\mailto}[1]{\href{mailto:#1}{\texttt{#1}}}

\let\stdsection\section         % because LaTeX cannot handle
                                % recursive commands
\renewcommand{\section}{\newpage\stdsection}

\let\tikzsquare\square
\renewcommand{\square}{\ensuremath\tikzsquare}

\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\buzz}[1]{\emph{#1}}
\newcommand{\magic}[1]{\buzz{#1}}

%% %%%%%%%%%%%%%%%%%%%% END COMMANDS %%%%%%%%%%%%%%%%%%%%

%% %%%%%%%%%%%%%%%%%%%% BEGIN COLORS %%%%%%%%%%%%%%%%%%%%

\definecolor{cffffff}{RGB}{255,255,255}
\definecolor{c787aff}{RGB}{120,122,255}
\definecolor{cff7374}{RGB}{255,115,116}
\definecolor{c79ff79}{RGB}{121,255,121}
\definecolor{cff7374}{RGB}{255,115,116}
\definecolor{c7372ff}{RGB}{115,114,255}

%% %%%%%%%%%%%%%%%%%%%% END COLORS %%%%%%%%%%%%%%%%%%%%


%% Final Report -- due: 9th Jan 2012, at 11:00
%% Contents for Final Report: The project report should not be longer than 45
%% pages, and might be organized according to the following structure:

%% A. High Level, Nontechnical Description Why you should buy this
%% product/listen to this presentation? What is the functionality of the product?
%% B. Short Technical Description
%% Short introduction into technologies used
%% Design of your software, possibly including a diagram of the major components
%% of the project
%% Main achievements
%% C. Software Engineering Issues:
%% What technology was used and why; what other technology was considered but
%% not used and why
%% Any technical challenges encountered and how addressed
%% Any risks anticipated, and how mitigated?
%% Any collaboration/coordination difficulties encountered and how addressed
%% Development and testing methods and/or tools used; comparison of plans with
%% actual achievements
%% Estimates of length of code in each of the components, or any other
%% comparable measure of the effort required.
%% Summary of each team member's contributions
%% D. Validation and Conclusions How did you validate your product? Was the
%% project successful? What did you learn? What might you have done differently?
%% E. Bibliography
%% F. Appendix The appendix is optional, and does not count towards the 45
%% pages. It may contain thing like: User guide, installation instructions; more
%% extensive design, testing, statistics etc.
%% Feel free to re-use material from the previous reports as you see fit, but
%% make sure that the final report presents a coherent story. Ask advice from your
%% supervisor. You might also draw inspiration from the instructions about writing
%% up your individual project.

%% Bear in mind, that most of the project assessors will not have followed the
%% project throughout and will only have a short time to listen to a presentation
%% or see a demonstration. For this reason they will rely heavily on the report to
%% judge the project.

%% The report should be submitted to SGO in form of a hard copy, as well as
%% electronically through CATE.

\begin{document}
\title{\Huge Visigoth\\\Large Graph visualisations}
\author{
  Andreea-Ingrid Funie\\\mailto{aif109@doc.ic.ac.uk}\and
  Alexandru Scvor\c tov\\\mailto{as10109@doc.ic.ac.uk}\and
  Francesco Mazzoli\\\mailto{fm2209@doc.ic.ac.uk}\and
  Marc-David Haubenstock\\\mailto{mh808@doc.ic.ac.uk}\and
  Maximilian Staudt\\\mailto{ms9109@doc.ic.ac.uk}
}
\date{January 2012}
\maketitle

\begin{abstract}
%% FIXME: This needs more work.

Visigoth is a tool to generate, analyse and visualise Small World
Networks. These are particular kinds of graphs which \emph{look} like
natural networks and share many mathematical properties with them.
For instance, the friendship graphs and graphs of followers in modern
web-based social networks are Small World Networks.

Visigoth is an educational tool that allows users to explore Small
World Networks and hence can be used when introducing them. By
exploring these networks, users will have a firmer, more intuitive
grasp of the mathematical properties they exhibit.

The networks may be generated by one of several algorithms which
allows users to compare the varying quality of their output. The
generated networks form a smooth progression in the number of
exhibited desired properties from completely random graphs ---
generated by the Erdos-Renyi algorithm --- to Small World Networks ---
generated by the Preferential Attachment algorithm. Additionally,
Visigoth can connect to social networking platforms such as Twitter to
display real networks.
\end{abstract}

\tableofcontents




\section{Introduction}
%% This section corresponds to A in the requirements.

%% This section should contain most of the references to hamm10 and
%% oconn11.

\subsection{Realistic looking networks}
%% This subsection should *not* use the term ``Small World Networks''.
%% The point is to describe what properties we want.  The SWN
%% subsection below should be used in order to explain how they fit
%% the requirements.

%% FIXME: Define the qualities of the networks we want.  These
%% shouldn't be too mathy, just a layperson explanation (e.g. the
%% nodes shouldn't be too far apart, the number of neighbours should
%% fit a natural distribution).

\subsubsection{Uses}

%% FIXME: Explain how networks with the above properties are useful.

\subsubsection{The maths}

%% FIXME: Give formal mathematical definitions for qualities.

\subsection{Small World Networks}

Small World Networks derive their denomination from the well-known
Small World Hypothesis\footnote{FIXME: citation needed}, which states
that any two persons are related through a chain of at most seven
friends\footnote{FIXME: citation needed}.

Indeed, Small World Networks are graphs resembling the connections
within human social networks, where nodes represent people, and edges
between nodes represent relations of some sort\footnote{FIXME:
  citation needed, probably one of the two main papers}.

For example, if someone were to draw every user\footnote{or at least a
  \emph{large} number of users} of a social network (e.g. Twitter) on
a canvas and then connect each pair of them if either is ``following''
the other or if they are ``friends'', the resulting graph is a Small
World Network. Over the course of time, several mathematical
algorithms that generate random Small World Networks have been
discovered. However, the resulting graphs have only lately begun to
resemble those that have grown naturally in the form of social
networks.

%% FIXME: Huh?  Are they really SWNs if they don't resemble the
%% natural graphs?  Not by our definition.  So, either the definition
%% is wrong, or the last two sentences need to be rewritten.

%% FIXME: Explain how SWNs exhibit *all* the properties we're
%% interested in.  Include some math.

\subsection{Introducing Visigoth}

Visigoth makes peeking into the current state-of-the-art of artificial
Small World Networks simple and fun. By integrating existing
generation algorithms and visualisations into a single, easy-to-use
interface, the user can make a head start into the small world of
Small World Networks and:
\begin{itemize}
  \item see how these algorithms have improved on each other over time
    generating increasingly better networks,
  \item see the effects of changing algorithm parameters on the
    resulting networks, and
  \item compare them to naturally grown networks.
\end{itemize}

\subsection{Customer requirements and iterative (re-)specification}

% What our customer wanted.
%
% What we suggested, and what he finally wanted.
% (E.g. once we suggested 3D he didn't want to let go of the idea)
%
% Finally, on overview of what we did, and what we added as a bonus.
% Possibly another subsection.

Our customer initially asked for a simple, easy-to-use, graphical
application that would allow him to compare various Small World
Network generation algorithms and parameters thereof, both visually
by looking at the graphs as well as numerically by calculating
several statistical properties of the graphs.
We suggested several additional features, such as a 3D view of the
graphs generated, real-world data fetching from social networks
(Twitter) and graph interaction. Following our customer's highly
positive reaction to our suggestions we then added them to our
product, creating a comprehensive base for analysing graphs that
may be re-used for other mathematical projects in the future.

\section{Collaboration and Coordination}

\subsection{Requirements and Pacing}

Visigoth is a highly complex and capable piece of software which has a lot of
interesting features. Inorder to have an efficient development process we
categorized requirements into \buzz{key} and \buzz{extensions}. A complete
list of these requirements are:

\begin{enumerate}

	\item Key
	\begin{itemize}
		\item	Real-time 2D graph renderer
		\item Several Random Network and Small World Network generation algorithms to
				choose from for the visualiser.
		\item Simple user interaction: zoom/pan the display, input basic graph
		generation parameters, rearrange nodes, add vertices (where the algorithm allows
		us to).
		\item User interaction using mouse or keyboard shortcuts.
		\item Statistics about generated networks.
	\end{itemize}

	\item Extensions
	\begin{itemize}
		\item Real-time 3D graph renderer.
		\item Choice of visualisation algorithms (e.g. highlight clusters, reveal most-connected nodes)
		\item Extended user input: more graph generation parameters, user editing of generated graphs
		\item "Save As" PDF
		\item Data mining existing networks (e.g. Twitter, academic citations)	

	\end{itemize}
\end{enumerate}

Inorder to help us determine the pace of our project we developed a schedule during the first week
of our project .\\
\includegraphics[scale=0.5]{schedule}

During our development process we have religously kept to this plan and we have hit every deadline
with target functionality and features.

\subsection{Development Methodologies}

The Visigoth team is \buzz{agile}, and we use the following methodologies: repeated short development cycles, evolutionary design and \buzz{scrum}.  We hold short review meetings in the spirit of scrum every few days, in which each of the team members mention what they are working on, what plans they have and what difficulties they have encountered. We also hold a meeting at the beginning of each week to measure our progress to adjust future plans; we measure progress by whether deadlines for planned features were met. We aim to implement all of the core features and at least 80 $\%$ of the extras.

Throughout the development process we have strived to use consistent style throughout the code and documentation. To this extent, it fell to the reviewer doing the merge to mention and fix any style issues. This has worked adequately most of the time, and in the few instances where badly styled code slipped through, subsequent \buzz{global} reviews remedied the problem in a timely fashion.

We do not assign specific roles to people; instead team members are rotated through all the roles (development, review/testing, documentation). This ensures that all members are familiar with the entire project.

\buzz{Git} is used for source and version control and we rely heavily on its versatile branching.  The slogan is "the master branch is always releasable"; in order to make a release, we need only build master. Changes are made on separate branches, and are only merged into master after going through code review. In addition to keeping master stable, this style of \buzz{continuous integration} allows us to work on several items at once and, via code review, ensures that at least two people are familiar with any piece of code. We plan to use \buzz{QuickCheck}-like property testing for the graph-generation algorithms and normal unit-testing for the user interface.


\subsection{People Management}

Visigoth Graph Visualisations covers a broad range of software engineering tasks, each with a different level of technical skill requirement. For instance, the kinds of problems we encountered are:
\begin{itemize}
	\item developing graph renderers (C/OpenGL and C/Cairo);
	\item UI programming (C++/Qt);
	\item implementing mathematical models (pen/paper);
	\item profiling and optimisations (valgrind, Google profiling tools);
	\item binding to various web services (OAuth/Twitter and REST/GitHub).
\end{itemize}

Hence, each member of the team is constantly being challenged individually. We also organise short technical talks to introduce other team members to concepts they may not be familiar with and which they may find useful. So far, we have done such talks on:
\begin{itemize}
	\item Git and branching hygiene;
	\item C++ and Qt.
\end{itemize}
If team members find they have resolved all issues currently assigned to them, then tasks such as log keeping and creating reports for the next deadline are always available.
As the following graph shows, code contributions have been mostly uniform across team members. The discrepancy in the first week is explained by the prototypes which we chose not to continue (whose code is not counted) and the effort expanded in understanding the mathematical foundations of network generation.

\includegraphics[scale=0.5]{work}


\begin{figure}[ht]
  \begin{minipage}[b]{0.5\linewidth}
\includegraphics[scale=0.5]{impact}
\caption{Changes in lines per commiter per week}
  \end{minipage}
\end{figure}

When working in a team, conflicts and debate are unavoidable. We try to keep all members engaged and interested at all times, however due to technical background and prior knowledge, some members are more suitable for some tasks than others. In such a case, the task gets assigned to the most qualified member. In other cases, we try to distribute tasks around the team to ensure that specific knowledge well-distributed across the team.

When conflicting opinions regarding the design of the system emerge, the team sits down and debates each solution. For now this system has worked very well, which is reflected in our projectâ€™s progress. In order to promote harmony, we have a sign much like the following in which we record our success.



%\section{In detail}
%% This section corresponds to B in the requirements

\section{Generating Small World Networks}
%% For all of the following, we should include a hand-drawn sketch
%% illustrating the graph generated by the algorithm and an exported
%% image of a large graph Visigoth generated.

\subsection{Erdos Renyi}

The Erd\H{o}s-R\'{e}nyi model, named for Paul Erd\"{o}s and Alfr\'{e}d R\'{e}nyi is an algorithm for
generation random networks. This is the simplest graph generation algorithm in
Visigoth's repertoire.

Edges in the network are created depending on a probability cutoff value which
can be set by the user. For every pair of nodes in the network, if a random
probability is below the cutoff value, the two nodes are connected.

This is implemented in the following way:
\begin{lstlisting}
    for (int i(0); i < size; ++i) {
        for (int j(i+1); j < size; ++j) {
            if ((double)qrand() / RAND_MAX < probability) {
                scene->newEdge(nodesVector[i], nodesVector[j]);
            } else {
                continue;
            }
        }
    }
\end{lstlisting}
\subsection{Watts Strogatz}

The Watts-Strogatz model is a graph generating model which generates random
graphs with small-world properties, which are, short average path length and
high clustering. It was proposed by Duncan J. Watts and Steven Strogatz in 1998.

The model operates in two steps:
First, generate a regular ring lattice with N nodes and K neighbours, K/2 on
each side.
\begin{lstlisting}
          QVector<Node*> nodeVec(size);
    for(int i(0); i < size; ++i){
        Node *node = scene->newNode();
        nodeVec[i] = node;    }
    // construct ring lattice
    for(int j(0); j < size; ++j) {
        // connecting right side
        for(int r(1); r<= degree/2; ++r) {
            int nodeToConnect = (j+r)%size;
            scene->newEdge(nodeVec[j], nodeVec[nodeToConnect]);
        }
        // connecting left side
        for(int l(1); l<= degree/2; ++l) {
            int nodeToConnect = (size+j-l)%size;
            scene->newEdge(nodeVec[j], nodeVec[nodeToConnect]);
        }
\end{lstlisting}

Then, for each edge, rewire it with probability $\beta$, where $0 \leq  \beta \leq 1$.
\begin{lstlisting}
 // rewire
    for(int n(0); n < size; ++n) {
        // only choose the right side, since we only select (ni,nj) with i < j
        for(int r(1); r <= degree/2; ++r) {
            int nodeToSelect = (n+r)%size;
            if ((double)qrand() / RAND_MAX < probability) {
                scene->removeEdge(nodeVec[n], nodeVec[nodeToSelect]);
                int newNode = qrand()%size;
                for (int cutOff(0);
                     cutOff < 1000 && !scene->newEdge(nodeVec[n], 					    nodeVec[newNode]);
                     ++cutOff) {
                    newNode = qrand()%size;
                }
            }
        }
    }
\end{lstlisting}

\subsection{Barabasi Albert}

The Barabasi-Albert model is an algorithm for generating scale-free networks
using preferential attachment. Nodes are selected for attachment with a
probability proportional to their
degree in the network.  Such networks are present in natural and human
made systems, such as the citation networks. 

A network is deemed scale-free if the network exhibits a power law degree
distribution. 
\[
degree(x) = ax^k
 \] 
In context, this means that the frequency of attachment to a node
varies as a power of its degree. Such networks are also scale invariant meaning
that the network's size has no effect on its attributes i.e. degree
distribution.

The model is implemented as follows:
\begin{enumerate}
\item Select a node by generating a random percentage with $2$ decimal place
precision.
The preferences of nodes are stored cumulatively therefore, the random number
serves as an index with the node as the indexed element, which can be accessed
using a binary search.
\begin{lstlisting}
    const float E = 0.01;
    int l;
    for (l = 1; l < nodes.size(); l <<= 1)
        ;
    int i(0);
    for (; l > 0; l >>= 1) {
        if (l + i < nodes.size()) {
            if (cumulativePreferences[l + i] <= genPref + E)
                i += l;
        }
    }
    return nodes[i];
\end{lstlisting}
  \item Attach the node to the indexed element.
  \item If more edges are to be added, repeat the procedure.
\begin{lstlisting}
    while (edgesToAdd > 0) {
        vPref = getPreference(nodes, genRandom());
        int cutOff;
        for (cutOff = 0; cutOff < 100 && !graph->newEdge(vertex, vPref);
             ++cutOff) {
            vPref = getPreference(nodes, genRandom());
        }
        if (cutOff == 100)
            break;
        --edgesToAdd;
        usedNodes << vPref;
        if (usedNodes.size() >= numNodes)
            break;
    }
\end{lstlisting}
  \item Recompute the preferences.
\begin{lstlisting}
    updatePreference(graph->nodes(), 2 * numEdges);
\end{lstlisting}
\end{enumerate}

\subsection{Bipartite Model}

A Bipartite graph is a graph which consists of two node sets. The nodes from
each set are only allowed to connect to nodes which are not a member of their
own set.

\footnote{http://en.wikipedia.org/wiki/File:Simple-bipartite-graph.svg}\includegraphics[scale=0.3]{bipartite}

The algorithm constructs a network in three simple steps
\begin{enumerate}
   \item Generate a bipartite graph with two node sets e.g. set U and set V.
   \item Connect all nodes in U that are connected to the same node in V.
   \item Remove the nodes from set V from the graph.
\end{enumerate}

This procedure is implemented as follows:
\begin{enumerate}
   \item Generate two node vectors, \code{uVector} and \code{vVector}.
\begin{lstlisting}
	for (int i(0); i < uSize; ++i) {
        	uVector << scene->newNode();
	}
	 for (int i(0); i < vSize; ++i) {
        	vVector << scene->newNode();
	}
\end{lstlisting}
   \item For each member of \code{vVector}, obtain it's degree distribution:
\code{double degree = degreeDist(i)} and add as many nodes from uVector as degree permits
   \item Connect any members of \code{uVector}, which are disjoint, to the network.
   \item Generate a set of vVector members, e.g. vector A, which are connected to some members of \code{uVector}
\begin{lstlisting}
       	foreach (Edge *e, scene->edges()) {
            	if (e->destNode()->tag() == v->tag()) {
                A << e;
            }
\end{lstlisting}
   \item For all members in vector A, connect nodes which share a common \code{vVector} member.
\begin{lstlisting}
	foreach (Edge *e1, A) {
            foreach (Edge *e2, A) {
                Node *u1 = e1->sourceNode();
                Node *u2 = e2->sourceNode();
                if (u1->tag() != u2->tag()){
                        scene->newEdge(u1,u2);
                }
            }
        }
\end{lstlisting}
   \item Remove all edges and nodes which are associated with a member of \code{vVector}.
\end{enumerate}

\subsection{Preferential Attachment}
Preferential attachment and clustering are two distinct concepts which are used in graph generation.
When using preferential attachment we assign nodes in a network a preference depending on their degree. Nodes with more edges, that is, which are more connected will have a higher preference than nodes with less edges. The preference ranges from ]0,1], assuming no disjoint nodes exist and, for a node N, is calculated as 
\[
\frac{N_\mathrm{edges}}{Total_\mathrm{edges}}
\]

Clustering is a concept which determines how to connect a node N, once a connection with at least one other node N' has been established. This procedure determines the intersection set of N' with all its neighbours. Then node N is connected to all members of the intersection set.

The algorithm described here uses both concepts to generate networks with scale-free characteristics. First, nodes are added to the network via the preferential attachment method then, once attached are connected to the rest of the network via the clustering procedure.

This is implemented as follows:
\begin{enumerate}
\item Select a node by generating a random percentage with 2 decimal place
precision.
The preferences of nodes are stored cumulatively therefore, the random number
serves as an index with the node as the indexed element, which can be accessed
using a binary search.
\begin{lstlisting}
    const float E = 0.01;
    int l;
    for (l = 1; l < nodes.size(); l <<= 1)
        ;
    int i(0);
    for (; l > 0; l >>= 1) {
        if (l + i < nodes.size()) {
            if (cumulativePreferences[l + i] <= genPref + E)
                i += l;
        }
    }
    return nodes[i];
\end{lstlisting}
   \item Attach the node to the indexed element.
   \item Use the clustering procedure to determine other edges.
\begin{lstlisting}
    int length = neighbours.size();
    while (edgesToAdd > 0 && !(neighbours.empty())) {
        int rand = qrand()%length;
        Node *vi = neighbours[rand];
        if (graph->newEdge(vertex, vi)) {
            --edgesToAdd;
            usedNodes << vi;
            neighbours = getIntersection(neighbours, vi->neighbours());
        } else {
            neighbours.remove(rand);
        }
        length = neighbours.size();
    }
   }  
\end{lstlisting}
   \item If more edges are to be added, repeat the procedure.
\begin{lstlisting}
    while (edgesToAdd > 0) {
	continue....
   }
\end{lstlisting}
   \item Recompute the preferences.
\begin{lstlisting}
	updatePreference(graph->nodes(), 2 * numEdges);
\end{lstlisting}

\end{enumerate}

\subsection{Real Small World Networks}
Finally, as Visigoth is supposed to help in analysing Small World
Networks, it can also fetch real world data from `live' social
networks Twitter and identi.ca.


\section{Statistics}


In addition to network generation Visigoth also calculates statistics about the
generated networks in real time. The statistics which are calculated are:


\begin{itemize}
	\item Average Degree
	\item Average Path Length
	\item Clustering Average
	\item Scale Free Exponent
	\item Clustering Coefficient
\end{itemize}

\subsection{Average Degree}
\[
\frac{2\sum_{i=1}^{\mathrm{max\ edges}} edges_i}{\sum_{j=1}^{\mathrm{max\
verticies}} vertecies_j}
\]

\begin{lstlisting}
return (2.0 * graph->edges().count()) / graph->nodes().count())
\end{lstlisting}

\subsection{Average Path Length}
\[
\frac{\sum_{i,j}distance_\mathrm{shortest}(verticie_i,verticie_j)}{\sum
vertices^2 - \sum vertices}
\]

The first step in this algorithms is to calculate the path length from every
node to every node

\begin{lstlisting}
foreach (Node *n, graph->nodes()) {
        allLengths += lengthSum(n, visited, distance);
	 ...
    }
\end{lstlisting}
Then divide the calculation by $k_i(k_i-1)$
\begin{lstlisting}
return allLengths/(double)(graph->nodes().size()*(graph->nodes().size()-1));
\end{lstlisting}

Here \code{lengthSum} is a sub procedure which traverses the network in a
breadth-first manner and calculates the minimum distance to each node.
It then returns the sum of all distances
\begin{lstlisting}
while(!queue.empty()) {
        Node *parent = queue.dequeue();
        QList<Edge*> edges = parent->edges();

        foreach(Edge *e, edges) {
            Node *n;

            if(e->sourceNode()->tag() == parent->tag()) {
                n = e->destNode();
            } else {
                n = e->sourceNode();
            }

            if(!visited.contains(n)) {
                visited.insert(n);
                distance[n] = distance.value(parent, 0) + 1;
                queue.enqueue(n);
            }

        }

        retLength += distance[parent];
    }

    return retLength;
\end{lstlisting}

\subsection{Clustering Coefficient}
\[
C_i = \frac{2|\{e_j,_k\}|}{k_i(k_i-1)}
\]
Where $k_i$ is the number of vertices immediately connected to $vertex_i$
\newline
The set ${e_j,_k}$ is set of all edges common to the neighbours of $vertex_i$\\

The first step is to calculate the intersection of the neighbours of the node wewant to calculate the statistic for and the neighbours of that node's neighbours\begin{lstlisting}
while (!edges.empty()) {
        Edge *e = edges.takeFirst();
        Node *src = e->sourceNode();
        Node *dest = e->destNode();
        QVector<Node*> nNeigh = node->neighbours();
        if(src->tag() == node->tag()) {
            QVector<Node*> dNeigh = dest->neighbours();
            intersection += intersectionCount(nNeigh, dNeigh);
        } else {
            QVector<Node*> dNeigh = src->neighbours();
            intersection += intersectionCount(nNeigh, dNeigh);
        }
    }
\end{lstlisting}
If the node's degree is greater than 1 we return the calculation.
\begin{lstlisting}
return k > 1 ? (2*intersection)/(double) (k*(k-1)):0 
\end{lstlisting}

\subsection{Clusering Average}
\[
C_\mathrm{avg} = \frac{1}{\mathrm{\sum vertecies}}\sum_{i=1}^{\mathrm{max\
vertecies}} C_i
\]
\begin{lstlisting}
 foreach (Node *n, graph->nodes()) {
        clusterCumulative += clusteringCoeff(n);
    }
    return clusterCumulative / (double)graph->nodes().size();
\end{lstlisting}

\subsection{Scale Free Exponent}

Before we are able to calculate any gradient Visigoth has to probe the network
and determine the degree distribution. Since we are dealing with exponential
growth, the algorithm takes the natural logarithm of both, the degree and its
frequency in the network, so that the gradient can be calculated as a straight
line.

\[
f(x) = ax^k \equiv ln(f(x)) = kln(a) + kln(x) \equiv y = mx + b
\]

\begin{lstlisting}
    for (double i(0); i < maxDegree; ++i) {
        double count = graph->nodeCount(i);
        double y = count / (double)graph->nodes().size();

        if (y != 0) {
            // incase we want to plot
            QPointF p(qLn(i+1), qLn(y));
            plot << p;
        }
    }
\end{lstlisting}

After the degree distribution has been recorded, the algorithm proceeds to
calculate the straight line gradient of the captured points.

\begin{lstlisting}
    foreach (QPointF p, plot) {
        // init calculation
        if (c == 0) {
           yPref = p.ry();
           deltaX = p.rx();
           ++c;
        } else {
            deltaY += p.ry() - yPref;
            yPref = p.ry();
            deltaX = p.rx() - deltaX;
            ++c;
        }
    }

    return (-1) * (deltaY / deltaX);
\end{lstlisting}

The result is multiplied by -1 since the straight line gradient is downwards
sloping.

\section{Visigoth technologies}

\subsection{Qt}

The UI toolkit, standard library replacement, and application
framework we used is Qt\footnote{FIXME: add link to the Qt Labs?
  website}.

\subsection{OpenGL}

After being left unsatisfied with the performance achieved with a
screen renderer using Qt graphics primitives, we looked for a `bare-metal'
graphics output solution in order to eliminate the graphics bottleneck.
Thanks to OpenGL\footnote{OpenGL documentation:
https://www.opengl.org/documentation/},
we can now draw even large graphs very quickly,
no matter whether in 2D or in 3D.

OpenGL itself is a graphics drawing interface commonly used to
leverage hardware acceleration for common operations, such as vector
transformations necessary to compute 3D graphics. Every modern
operating system uses it to animate its user interface smoothly,
and games and professional CAD (Computer Assisted Design) applications
have long used it for real-time 3D graphics interaction.

Not only are we leveraging this power to speed up our graph
visualiser, but this may also allow for ports to other
platforms in the future. Thanks to the Qt/OpenGL base, Visigoth
could theoretically be compiled for mobile phones and slates
with minimal porting effort.

OpenGL made several extensions possible, as outlined in the following
subsections.

\subsubsection{3D graphs and camera}
OpenGL provides only the very fundamental drawing primitives like
lines and points - however, it includes hardware acceleration for
vector transformation. This allows the implementation of a virtual
3D space through which a `camera' can move. As even this is actually
a composite functionality, we wrote a helper code library (glAncillary)
to provide us with easy camera transformation functions. They are
used whenever the user decides to move around the graph, i.e. to
pan or tilt.

\subsubsection{Selection}
The OpenGL interface also eases object selection: Since it is
responsible for the depth transformations when drawing the graphics,
it can also perform the inverse of these transformations from any
given point on the drawing surface, finding the original point
in space. In this case we check the position the mouse pointer is at
and find the object selected by the user. This is fundamental in
allowing us to move nodes around and selecting them for statistical
analysis.

\subsection{C++}

Visigoth, ignoring the XML files describing the interface, is entirely
written in \buzz{C++}. Initially, while being conscious of its disadvantages,
we made this decision for one reason: \buzz{Qt}. As described in the previous
paragraph, the library by TrollTech is so convenient that alone
justifies the use of C++ instead of another safer language.

All in all, we think it was the right decision. The appreciation of
C++ varies in our team, but looking back we are confident that C++ was
one of the best choices considering the nature of the application we
have been developing.

The main advantages were:

\begin{description}

\item [Availability of tools and library] As mentioned, \buzz{Qt} alone
  was a deal sealer, but the fact that we were able to access OpenGL
  `natively' (in a Qt widget) was also a big advantage. While interfaces
  to both libraries exist in other languages as well, we felt that
  sticking to Qt's `native' C++ environment would be the most stable
  solution and that the foreign language bindings would have degraded
  performance.

\item [Performance] We did not consider this factor at the beginning,
  but a few weeks into the project we started hitting various
  bottlenecks. We can only speculate about actual performance gains,
  but the fact that we were using
  C++ allowed us to fine-tune the application (specifically on the
  memory management side) in a way that we would not be able to do
  with managed languages. Furthermore, having an optimising compiler
  instead of an interpreter or JIT (as it would have been the case
  using a language like Python or Ruby) aided performance as well.

\item [Abstraction] The previous two points (especially the second)
  are partly shared by C++ with its predecessor, C. However, the
  possibility to structure our code into classes facilitates greatly
  structuring a medium sized application like Visigoth, especially
  considering that we had to coordinate five people working together.
  For example, there is a common \code{Algorithm} interface which all
  graph generation algorithms have to implement. They can then
  be plugged into the main widget at will: this kind of operation
  would have been much more laborious and less type-safe in C.

\end{description}

However, C++ also has its downsides:

\begin{description}

\item [Unmanaged memory] This is by far C++'s most ``dangerous''
  feature (or better, lack of feature). While enabling greater control
  and thus greater performance, it requires a much more attentive
  analysis of the code. This is in a way a good thing, since it forces
  the programmer to reason more about what the code is doing; but it
  also paves the way to a nasty class of bugs and memory leaks that
  more than once took hours (in one case days) to track down. This is
  a somewhat controversial subject in our team as well as the broader
  programming community and our opinions differ on how much better a
  garbage collected language would have been when considering the loss in
  performance. C++ also has the characteristic (required by its
  unmanaged nature) of allowing objects to be used in the heap through
  pointers and on the stack as values, which slows down compilation
  considerably - when changing a header file, all code that uses
  that object as a value has to be recompiled. Moreover, C++ allows two
  kinds of references: immutable references and C-style pointers, the
  former with
  a rather confusing syntax - references are indistinguishable from
  values when used. All these factors generate much confusion which is
  absent in most modern O-O languages.

\item [Language bloat] C++ is a very broad language with a number of
  esoteric language features. Notable examples are templates, operator
  overloading and ``friend'' attributes. Some of them are very
  useful and never harmful, e.g. the \code{const} keyword is a
  great mechanism to mark immutability at type level. However, some
  of them can and have been misused\footnote{For an hilarious example,
    see
    \url{http://weegen.home.xs4all.nl/eelis/analogliterals.xhtml}},
  and as a consequence ``when you're programming C++ no one can ever
  agree on which ten percent of the language is safe to use'' (Jamie
  Zawinski). This kind of ``programming language discipline'' is
  required when working on a C++ project and we had our fair share
  of arguments on which subset of the language is safe to use;
  nevertheless we think we have managed to keep the code clean to
  high standards in the C++ world.

\end{description}

This is of course only a very brief analysis of C++, but it does
highlight the points that we felt the most while developing Visigoth.




\section{Engineering Visigoth}
%% This section corresponds to C in the requirements

\subsection{Graph drawing}

We looked into various graphics libraries which allow for
platform-independent drawing using primitives. Candidates were
\buzz{Cairo}\footnote{Cairo homepage: http://cairographics.org/},
\buzz{Qt} and \buzz{OpenGL}. The first two are the
most common 2D drawing libraries used in modern open-source
software; however, as they operate solely on the CPU, they proved
too slow for the large graphs we wished to visualise.

Therefore we decided to use \buzz{OpenGL} for drawing graphs on
the screen. Thanks to its hardware accelerated nature, we can now
(re-)draw thousands of nodes and edges often enough every second
to give the user the impression of a smooth interface when interacting
with the graph.

Implementing the camera handling, the node/edge drawing and the
interface allowing the user to `fly' through a 3D graph we also
developed a helper library, \code{glAncillary}. A significant portion
of our code can now be reused in similar projects using OpenGL,
and this is important since applications such as Visigoth require a
completely different type of graphics engine compared to the ones
commonly found e.g. in video games.


\subsection{Graph layout}
Laying out a graph is a tricky problem, mainly due to the fact that the
prime interest when engineering layouts is to please humans' taste
instead of some logical property. A wide array of such algorithms have
been proposed, and since drawing graphs is a central task in Visigoth,
we had to choose the one that fit best.

First we experimented with the existing solutions. One of the most
complete free graph-drawing algorithm is
OpenViz\footnote{\url{http://www.graphviz.org/}}, and it provides
various algorithms:

\begin{description}
\item [dot] A hierarchical layout, used for directed graphs. Our small
  world networks are not directed and it was clear from the beginning
  that they did not fit this model well.

\item [twopi, circo] Radial and circular layout, respectively. Again,
  unsuitable for the quasi-random networks that we use in Visigoth.

\item [neato] A spring model layout, which seemed to work reasonably
  well with random graphs.
\end{description}

The spring model seemed to be the best fit. This class of algorithm
work by treating edges like springs: in this way clusters of highly
connected nodes would be drawn together. To counter this force (that
would lead to nodes lumping together), nodes are treated as charged
particles of the same polarity, causing repulsion between every node
and the others.

When generating a graph, the nodes are first places at random
locations in the space. Then, we apply the algorithm repeatedly until
the forces are low enough that we can consider the graph to be stable.

Spring model algorithms are nice for two reasons:

\begin{itemize}
\item Good results: spring force algorithms produce pleasant graphs
  for almost all kind of networks. Some algorithms might produce
  better results for specific kinds of graph, but spring force
  algorithms are by far the more adaptive.

\item Ease of implementation: Our simple implementation of the
  algorithm take a little less then 50 lines of C++ code, and works
  well up to medium-sized graphs.

\item Real time drawing: force based algorithms can be used to show in
  real time the untangling of the graph, which is usually an
  interesting effect. It also permits interaction, for example in the
  form of node-dragging that changes the shape of the graph. We employ
  both techniques in Visigoth.
\end{itemize}

\subsubsection{FADE}

However, even a simple description of the algorithms reveals its high
cost. For each particle, we need to iterate through all the connected
nodes to calculate the spring forces, and more importantly through all
the particles of the graphs to calculate the repulsion forces. Thus,
the algorithm is \(O(n^2)\), where \(n\) is the number of nodes.

For this reason, our implementation works smoothly up to around a
\(1000\) nodes, but then performance degrades quickly, and the program
becomes unresponsive. Various solutions have been studied, most of
which rely on various approximations.

We chose to implement the \emph{FADE} algorithm \cite{fade}, which works by
recursively subdividing the graph space into sub-spaces, and then
treats sub-spaces as single particles when they are far enough. This
algorithm, while improving performance, is a lot more complex then the
naive one.

\begin{figure}
  \centering
  \subfloat[Graph view]{
    \input{quadtree-graph.tex}
  }
  \hspace{10pt}
  \subfloat[Tree representation]{
    \input{quadtree-tree.tex}
  }
  \caption{The QuadTree for a sample graph, empty branches omitted}
  \label{fig:quadtree}
\end{figure}

The first step is to build a data structure representing the recursive
subdivision. This kind of data structure is called a \emph{TreeCode},
which recursively subdivides the space until only one node remains in
the current space, or a maximum depth/minimum space size size is
hit. The space decomposition can be irregular (e.g. \emph{Voronoi}
spaces) or regular. In the latter case, the space is recursively
subdivided in squares. We chose to use a regular, 4-way space
decomposition, mainly due to its simplicity. This kind of structure is
called \emph{QuadTree}. Figure \ref{fig:quadtree} shows a sample
QuadTree for a Visigoth graph. In the QuadTree, each sub-quadrant
preserved the weighted centre of gravity relative to the contained
nodes.

Building the tree is the difficult part of the algorithm and can be
done in linear time. Once that is done, to calculate the non-edge
forces for a given node the algorithm proceeds as indicated in figure
\ref{proc:FADE}.

\begin{figure}[ht]
  \begin{minipage}[b]{0.5\linewidth}
    \input{fade-algorithm.tex}
    \caption{This procedure calculates the non-edge force of a given
      node \(n\), given the QuadTree \(q\). \(\vec{n}\) and
      \(\vec{q}\) indicate the vectors corresponding to the respective
      centers of gravity. \(\beta\) is an empirically determined
      parameter used to regulate the amount of force - \(75\) has
      worked well for us. \(\theta\) is central to the FADE algorithm
      and determines the amount of approximation. If \(\geq 1\) the
      algorithm is unstable, we used values between \(0.5\) and
      \(0.8\). See figure \ref{fig:theta} for a visual
      explanation. The mass of a quadrant is simply the number of
      nodes residing in it. }
    \label{proc:FADE}
  \end{minipage}
  \hspace{10pt}
  \begin{minipage}[b]{0.5\linewidth}
    \centering
    \input{fade-distance.tex}
    \caption{In this case, \(n_1\) and \(n_2\) are nodes and \(q\) is
      a quadrant with edge length \(s\). When calculating the non-edge
      force between \(n_1\) and \(q\), where \(s\) is the quadrant
      will be judged to be too close to approximate, since
      \(\frac{s}{d_1} > 1\), while \(n_2\) might be judged far enough,
      depending on \(\theta\).}
    \label{fig:theta}
  \end{minipage}
\end{figure}

Once implemented, the FADE algorithm lead to great speedups while
preserving good node placements. While drawing \(1000\) nodes is
already difficult with the simple algorithm, FADE can easily handle
\(10000\) nodes, after which other performance limits are hit (the
graph generation time and the OpenGL drawing).

After we implemented the 3D view we had to write an extension to FADE to support3D, which proved to be straight forward. Now we have a 3-dimensional space,
which is recursively divided into $8$ cubes.

\section{Looking back}
%% This section corresponds to 'Conclusions' in part D of the requirements

\subsection{Validation}
%% The client is a happy puppy

\subsection{Lessons learned}

\addcontentsline{toc}{section}{References}
\begin{thebibliography}{9}

\bibitem{hamm10}
  David A. Hammond,
  \emph{Altruism in Small World Models}.
  Imperial College London,
  2010.

\bibitem{oconn11}
  Luke M. O'Connor,
  \emph{Algorithms for Constructing Realistic Networks}.
  Imperial College London,
  2011.

\bibitem{fade}
  Aaron Quigley and Peter Eades,
  \emph{FADE: Graph drawing, clustering and visual abstraction}.
  Department of Computer Science and Software Engineering,
  Univ. of  Newcastle, Australia, 2000.

\end{thebibliography}

\end{document}
